{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e72ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchflare.experiments import Experiment, ModelConfig\n",
    "import torchflare.callbacks as cbs\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d95e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd332a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, batchnorm=True):\n",
    "        \"\"\"A generator for mapping a latent space to a sample space.\n",
    "        The sample space for this generator is single-channel, 28x28 images\n",
    "        with pixel intensity ranging from -1 to +1.\n",
    "        Args:\n",
    "            latent_dim (int): latent dimension (\"noise vector\")\n",
    "            batchnorm (bool): Whether or not to use batch normalization\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batchnorm = batchnorm\n",
    "        self._init_modules()\n",
    "\n",
    "    def _init_modules(self):\n",
    "        \"\"\"Initialize the modules.\"\"\"\n",
    "        # Project the input\n",
    "        self.linear1 = nn.Linear(self.latent_dim, 256*7*7, bias=False)\n",
    "        self.bn1d1 = nn.BatchNorm1d(256*7*7) if self.batchnorm else None\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "\n",
    "        # Convolutions\n",
    "        self.conv1 = nn.Conv2d(\n",
    "                in_channels=256,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "                bias=False)\n",
    "        self.bn2d1 = nn.BatchNorm2d(128) if self.batchnorm else None\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.bn2d2 = nn.BatchNorm2d(64) if self.batchnorm else None\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(\n",
    "                in_channels=64,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map latent vectors to samples.\"\"\"\n",
    "        intermediate = self.linear1(input_tensor)\n",
    "        intermediate = self.bn1d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = intermediate.view((-1, 256, 7, 7))\n",
    "\n",
    "        intermediate = self.conv1(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d1(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        if self.batchnorm:\n",
    "            intermediate = self.bn2d2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "\n",
    "        intermediate = self.conv3(intermediate)\n",
    "        output_tensor = self.tanh(intermediate)\n",
    "        return output_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        \"\"\"A discriminator for discerning real from generated images.\n",
    "        Images must be single-channel and 28x28 pixels.\n",
    "        Output activation is Sigmoid.\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self._init_modules()  # I know this is overly-organized. Fight me.\n",
    "\n",
    "    def _init_modules(self):\n",
    "        \"\"\"Initialize the modules.\"\"\"\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=64,\n",
    "            kernel_size=5,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            bias=True,\n",
    "        )\n",
    "        self.leaky_relu = nn.LeakyReLU()\n",
    "        self.dropout_2d = nn.Dropout2d(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=5,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            bias=True,\n",
    "        )\n",
    "\n",
    "        self.linear1 = nn.Linear(128 * 7 * 7, self.output_dim, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"Forward pass; map samples to confidence they are real [0, 1].\"\"\"\n",
    "        intermediate = self.conv1(input_tensor)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "\n",
    "        intermediate = self.conv2(intermediate)\n",
    "        intermediate = self.leaky_relu(intermediate)\n",
    "        intermediate = self.dropout_2d(intermediate)\n",
    "\n",
    "        intermediate = intermediate.view((-1, 128 * 7 * 7))\n",
    "        intermediate = self.linear1(intermediate)\n",
    "        output_tensor = self.sigmoid(intermediate)\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67723ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANExperiment(Experiment):\n",
    "    def __init__(self, latent_dim, batch_size, **kwargs):\n",
    "\n",
    "        super(DCGANExperiment, self).__init__(**kwargs)\n",
    "\n",
    "        self.noise_fn = lambda x: torch.randn((x, latent_dim), device=self.device)\n",
    "        self.target_ones = torch.ones((batch_size, 1), device=self.device)\n",
    "        self.target_zeros = torch.zeros((batch_size, 1), device=self.device)\n",
    "\n",
    "    def train_step(self):\n",
    "\n",
    "        latent_vec = self.noise_fn(self.batch[self.input_key].shape[0])\n",
    "\n",
    "        self.state.optimizer[\"discriminator\"].zero_grad()\n",
    "        pred_real = self.state.model[\"discriminator\"](self.batch[self.input_key])\n",
    "\n",
    "        loss_real = self.state.criterion(pred_real, self.target_ones)\n",
    "\n",
    "        fake = self.state.model[\"generator\"](latent_vec)\n",
    "        pred_fake = self.state.model[\"discriminator\"](fake.detach())\n",
    "        loss_fake = self.state.criterion(pred_fake, self.target_zeros)\n",
    "\n",
    "        loss_d = (loss_real + loss_fake) / 2\n",
    "        loss_d.backward()\n",
    "\n",
    "        self.state.optimizer[\"discriminator\"].step()\n",
    "\n",
    "        # Generator Training\n",
    "\n",
    "        self.state.optimizer[\"generator\"].zero_grad()\n",
    "        classifications = self.state.model[\"discriminator\"](fake)\n",
    "        loss_g = self.state.criterion(classifications, self.target_ones)\n",
    "        loss_g.backward()\n",
    "        self.state.optimizer[\"generator\"].step()\n",
    "\n",
    "        self.loss_per_batch = {\"loss_d\": loss_d.item(), \"loss_g\": loss_g.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n",
    "latent_dim = 16\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b81e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config = ModelConfig(\n",
    "    nn_module={\"discriminator\": Discriminator, \"generator\": Generator},\n",
    "    module_params={\n",
    "        \"discriminator\": {\"output_dim\": 1},\n",
    "        \"generator\": {\"latent_dim\": latent_dim},\n",
    "    },\n",
    "    optimizer={\"discriminator\": \"Adam\", \"generator\": \"Adam\"},\n",
    "    optimizer_params={\"discriminator\": dict(lr=1e-3), \"generator\": dict(lr=2e-4)},\n",
    "    criterion=\"binary_cross_entropy\",\n",
    ")\n",
    "\n",
    "callbacks = [cbs.ModelCheckpoint(mode=\"min\", monitor=\"train_loss_g\", save_dir=\"./\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347330d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tv.transforms.Compose(\n",
    "    [\n",
    "        tv.transforms.Grayscale(num_output_channels=1),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")\n",
    "dataset = ImageFolder(root=os.path.join(\"mnist_png\", \"training\"), transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = DCGANExperiment(\n",
    "    latent_dim=latent_dim,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=1,\n",
    "    device=\"cuda\",\n",
    "    seed=42,\n",
    "    fp16=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.compile_experiment(model_config=exp_config, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d080f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.fit_loader(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
