{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on Tabular Data using torchflare\n",
    "***\n",
    "* Dataset: https://www.kaggle.com/c/cat-in-the-dat-ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import traceback\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from torchflare.experiments import Experiment\n",
    "import torchflare.metrics as metrics\n",
    "import torchflare.callbacks as cbs\n",
    "import torchflare.criterion as crit\n",
    "from torchflare.datasets import SimpleDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"def reduce_mem_usage(df, verbose=True):\\n    '''\\n    Reduce file memory usage\\n    Source: https://www.kaggle.com/artgor\\n    \\n    Parameters:\\n    -----------\\n    df: DataFrame\\n        Dataset on which to perform transformation\\n    verbose: bool\\n        Print additional information\\n    Returns:\\n    --------\\n    DataFrame\\n        Dataset as pandas DataFrame\\n    '''\\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\\n    start_mem = df.memory_usage().sum() / 1024**2\\n    for col in df.columns:\\n        col_type = df[col].dtypes\\n        if col_type in numerics:\\n            c_min = df[col].min()\\n            c_max = df[col].max()\\n            if str(col_type)[:3] == 'int':\\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\\n                    df[col] = df[col].astype(np.int8)\\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\\n                    df[col] = df[col].astype(np.int16)\\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\\n                    df[col] = df[col].astype(np.int32)\\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\\n                    df[col] = df[col].astype(np.int64)\\n            else:\\n                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16)\\\\\\n                                               .max and c_prec == np.finfo(np.float16).precision:\\n                    df[col] = df[col].astype(np.float16)\\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32)\\\\\\n                                                .max and c_prec == np.finfo(np.float32).precision:\\n                    df[col] = df[col].astype(np.float32)\\n                else:\\n                    df[col] = df[col].astype(np.float64)\\n    end_mem = df.memory_usage().sum() / 1024**2\\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'\\\\\\n                                               .format(end_mem, 100 * (start_mem - end_mem) / start_mem))\\n    \\n    return (df)\";\n",
       "                var nbb_formatted_code = \"def reduce_mem_usage(df, verbose=True):\\n    \\\"\\\"\\\"\\n    Reduce file memory usage\\n    Source: https://www.kaggle.com/artgor\\n    \\n    Parameters:\\n    -----------\\n    df: DataFrame\\n        Dataset on which to perform transformation\\n    verbose: bool\\n        Print additional information\\n    Returns:\\n    --------\\n    DataFrame\\n        Dataset as pandas DataFrame\\n    \\\"\\\"\\\"\\n    numerics = [\\\"int16\\\", \\\"int32\\\", \\\"int64\\\", \\\"float16\\\", \\\"float32\\\", \\\"float64\\\"]\\n    start_mem = df.memory_usage().sum() / 1024 ** 2\\n    for col in df.columns:\\n        col_type = df[col].dtypes\\n        if col_type in numerics:\\n            c_min = df[col].min()\\n            c_max = df[col].max()\\n            if str(col_type)[:3] == \\\"int\\\":\\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\\n                    df[col] = df[col].astype(np.int8)\\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\\n                    df[col] = df[col].astype(np.int16)\\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\\n                    df[col] = df[col].astype(np.int32)\\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\\n                    df[col] = df[col].astype(np.int64)\\n            else:\\n                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\\n                if (\\n                    c_min > np.finfo(np.float16).min\\n                    and c_max < np.finfo(np.float16).max\\n                    and c_prec == np.finfo(np.float16).precision\\n                ):\\n                    df[col] = df[col].astype(np.float16)\\n                elif (\\n                    c_min > np.finfo(np.float32).min\\n                    and c_max < np.finfo(np.float32).max\\n                    and c_prec == np.finfo(np.float32).precision\\n                ):\\n                    df[col] = df[col].astype(np.float32)\\n                else:\\n                    df[col] = df[col].astype(np.float64)\\n    end_mem = df.memory_usage().sum() / 1024 ** 2\\n    if verbose:\\n        print(\\n            \\\"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\\\".format(\\n                end_mem, 100 * (start_mem - end_mem) / start_mem\\n            )\\n        )\\n\\n    return df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    '''\n",
    "    Reduce file memory usage\n",
    "    Source: https://www.kaggle.com/artgor\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: DataFrame\n",
    "        Dataset on which to perform transformation\n",
    "    verbose: bool\n",
    "        Print additional information\n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame\n",
    "        Dataset as pandas DataFrame\n",
    "    '''\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16)\\\n",
    "                                               .max and c_prec == np.finfo(np.float16).precision:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32)\\\n",
    "                                                .max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'\\\n",
    "                                               .format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"train_df = pd.read_csv(\\\"./dataset/train.csv\\\")\\nfeatures = train_df.columns.difference([\\\"id\\\", \\\"target\\\"]).tolist()\\ntarget = \\\"target\\\"\";\n",
       "                var nbb_formatted_code = \"train_df = pd.read_csv(\\\"./dataset/train.csv\\\")\\nfeatures = train_df.columns.difference([\\\"id\\\", \\\"target\\\"]).tolist()\\ntarget = \\\"target\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./dataset/train.csv\")\n",
    "features = train_df.columns.difference([\"id\", \"target\"]).tolist()\n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 19.46 Mb (83.0% reduction)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"label_encoders = {}\\nfor cat_col in features:\\n    label_encoders[cat_col] = LabelEncoder()\\n    train_df[cat_col] = label_encoders[cat_col].fit_transform(\\n        train_df[cat_col].astype(\\\"category\\\").cat.codes.fillna(-1).values\\n    )\\n\\ntrain_df = reduce_mem_usage(train_df)\";\n",
       "                var nbb_formatted_code = \"label_encoders = {}\\nfor cat_col in features:\\n    label_encoders[cat_col] = LabelEncoder()\\n    train_df[cat_col] = label_encoders[cat_col].fit_transform(\\n        train_df[cat_col].astype(\\\"category\\\").cat.codes.fillna(-1).values\\n    )\\n\\ntrain_df = reduce_mem_usage(train_df)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_encoders = {}\n",
    "for cat_col in features:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    train_df[cat_col] = label_encoders[cat_col].fit_transform(\n",
    "        train_df[cat_col].astype(\"category\").cat.codes.fillna(-1).values\n",
    "    )\n",
    "\n",
    "train_df = reduce_mem_usage(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"cat_dims = [int(train_df[col].nunique()) for col in features]\\nemb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]\";\n",
       "                var nbb_formatted_code = \"cat_dims = [int(train_df[col].nunique()) for col in features]\\nemb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_dims = [int(train_df[col].nunique()) for col in features]\n",
    "emb_dims = [(x, min(50, (x + 1) // 2)) for x in cat_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"train_df, valid_df = train_test_split(train_df, test_size=0.3, stratify=train_df.target)\";\n",
       "                var nbb_formatted_code = \"train_df, valid_df = train_test_split(train_df, test_size=0.3, stratify=train_df.target)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size=0.3, stratify=train_df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class Model(nn.Module):\\n    def __init__(\\n        self, emb_dims, lin_layer_sizes, output_size, emb_dropout, lin_layer_dropouts\\n    ):\\n        \\\"\\\"\\\"\\n        emb_dims: List of two element tuples\\n        For each categorical feature the first element of a tuple will\\n        denote the number of unique values of the categorical\\n        feature. The second element will denote the embedding\\n        dimension to be used for that feature.\\n        \\\"\\\"\\\"\\n\\n        super(Model, self).__init__()\\n\\n        # Embedding layers\\n        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\\n        self.no_of_embs = sum([y for x, y in emb_dims])\\n\\n        # Linear Layers\\n        first_lin_layer = nn.Linear(\\n            in_features=self.no_of_embs, out_features=lin_layer_sizes[0]\\n        )\\n\\n        self.lin_layers = nn.ModuleList(\\n            [first_lin_layer]\\n            + [\\n                nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\\n                for i in range(len(lin_layer_sizes) - 1)\\n            ]\\n        )\\n\\n        for lin_layer in self.lin_layers:\\n            nn.init.kaiming_normal_(lin_layer.weight.data)\\n\\n        # Output Layer\\n        self.output_layer = nn.Linear(lin_layer_sizes[-1], output_size)\\n        nn.init.kaiming_normal_(self.output_layer.weight.data)\\n\\n        # Batch Norm Layers\\n        self.first_bn_layer = nn.BatchNorm1d(self.no_of_embs)\\n        self.bn_layers = nn.ModuleList(\\n            [nn.BatchNorm1d(size) for size in lin_layer_sizes]\\n        )\\n\\n        # Dropout Layers\\n        self.emb_dropout_layer = nn.Dropout(emb_dropout)\\n        self.droput_layers = nn.ModuleList(\\n            [nn.Dropout(size) for size in lin_layer_dropouts]\\n        )\\n\\n    def forward(self, cat_data):\\n\\n        if self.no_of_embs != 0:\\n            x = [\\n                emb_layer(cat_data[:, i]) for i, emb_layer in enumerate(self.emb_layers)\\n            ]\\n            x = torch.cat(x, 1)\\n            x = self.first_bn_layer(x)\\n            x = self.emb_dropout_layer(x)\\n\\n        for lin_layer, dropout_layer, bn_layer in zip(\\n            self.lin_layers, self.droput_layers, self.bn_layers\\n        ):\\n\\n            x = F.relu(lin_layer(x))\\n            x = dropout_layer(x)\\n            x = bn_layer(x)\\n\\n        x = self.output_layer(x)\\n        return x\";\n",
       "                var nbb_formatted_code = \"class Model(nn.Module):\\n    def __init__(\\n        self, emb_dims, lin_layer_sizes, output_size, emb_dropout, lin_layer_dropouts\\n    ):\\n        \\\"\\\"\\\"\\n        emb_dims: List of two element tuples\\n        For each categorical feature the first element of a tuple will\\n        denote the number of unique values of the categorical\\n        feature. The second element will denote the embedding\\n        dimension to be used for that feature.\\n        \\\"\\\"\\\"\\n\\n        super(Model, self).__init__()\\n\\n        # Embedding layers\\n        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\\n        self.no_of_embs = sum([y for x, y in emb_dims])\\n\\n        # Linear Layers\\n        first_lin_layer = nn.Linear(\\n            in_features=self.no_of_embs, out_features=lin_layer_sizes[0]\\n        )\\n\\n        self.lin_layers = nn.ModuleList(\\n            [first_lin_layer]\\n            + [\\n                nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\\n                for i in range(len(lin_layer_sizes) - 1)\\n            ]\\n        )\\n\\n        for lin_layer in self.lin_layers:\\n            nn.init.kaiming_normal_(lin_layer.weight.data)\\n\\n        # Output Layer\\n        self.output_layer = nn.Linear(lin_layer_sizes[-1], output_size)\\n        nn.init.kaiming_normal_(self.output_layer.weight.data)\\n\\n        # Batch Norm Layers\\n        self.first_bn_layer = nn.BatchNorm1d(self.no_of_embs)\\n        self.bn_layers = nn.ModuleList(\\n            [nn.BatchNorm1d(size) for size in lin_layer_sizes]\\n        )\\n\\n        # Dropout Layers\\n        self.emb_dropout_layer = nn.Dropout(emb_dropout)\\n        self.droput_layers = nn.ModuleList(\\n            [nn.Dropout(size) for size in lin_layer_dropouts]\\n        )\\n\\n    def forward(self, cat_data):\\n\\n        if self.no_of_embs != 0:\\n            x = [\\n                emb_layer(cat_data[:, i]) for i, emb_layer in enumerate(self.emb_layers)\\n            ]\\n            x = torch.cat(x, 1)\\n            x = self.first_bn_layer(x)\\n            x = self.emb_dropout_layer(x)\\n\\n        for lin_layer, dropout_layer, bn_layer in zip(\\n            self.lin_layers, self.droput_layers, self.bn_layers\\n        ):\\n\\n            x = F.relu(lin_layer(x))\\n            x = dropout_layer(x)\\n            x = bn_layer(x)\\n\\n        x = self.output_layer(x)\\n        return x\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, emb_dims, lin_layer_sizes, output_size, emb_dropout, lin_layer_dropouts\n",
    "    ):\n",
    "        \"\"\"\n",
    "        emb_dims: List of two element tuples\n",
    "        For each categorical feature the first element of a tuple will\n",
    "        denote the number of unique values of the categorical\n",
    "        feature. The second element will denote the embedding\n",
    "        dimension to be used for that feature.\n",
    "        \"\"\"\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Embedding layers\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(x, y) for x, y in emb_dims])\n",
    "        self.no_of_embs = sum([y for x, y in emb_dims])\n",
    "\n",
    "        # Linear Layers\n",
    "        first_lin_layer = nn.Linear(\n",
    "            in_features=self.no_of_embs, out_features=lin_layer_sizes[0]\n",
    "        )\n",
    "\n",
    "        self.lin_layers = nn.ModuleList(\n",
    "            [first_lin_layer]\n",
    "            + [\n",
    "                nn.Linear(lin_layer_sizes[i], lin_layer_sizes[i + 1])\n",
    "                for i in range(len(lin_layer_sizes) - 1)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for lin_layer in self.lin_layers:\n",
    "            nn.init.kaiming_normal_(lin_layer.weight.data)\n",
    "\n",
    "        # Output Layer\n",
    "        self.output_layer = nn.Linear(lin_layer_sizes[-1], output_size)\n",
    "        nn.init.kaiming_normal_(self.output_layer.weight.data)\n",
    "\n",
    "        # Batch Norm Layers\n",
    "        self.first_bn_layer = nn.BatchNorm1d(self.no_of_embs)\n",
    "        self.bn_layers = nn.ModuleList(\n",
    "            [nn.BatchNorm1d(size) for size in lin_layer_sizes]\n",
    "        )\n",
    "\n",
    "        # Dropout Layers\n",
    "        self.emb_dropout_layer = nn.Dropout(emb_dropout)\n",
    "        self.droput_layers = nn.ModuleList(\n",
    "            [nn.Dropout(size) for size in lin_layer_dropouts]\n",
    "        )\n",
    "\n",
    "    def forward(self, cat_data):\n",
    "\n",
    "        if self.no_of_embs != 0:\n",
    "            x = [\n",
    "                emb_layer(cat_data[:, i]) for i, emb_layer in enumerate(self.emb_layers)\n",
    "            ]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.first_bn_layer(x)\n",
    "            x = self.emb_dropout_layer(x)\n",
    "\n",
    "        for lin_layer, dropout_layer, bn_layer in zip(\n",
    "            self.lin_layers, self.droput_layers, self.bn_layers\n",
    "        ):\n",
    "\n",
    "            x = F.relu(lin_layer(x))\n",
    "            x = dropout_layer(x)\n",
    "            x = bn_layer(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"model = Model(emb_dims, lin_layer_sizes=[300, 300],\\n                   output_size=1, emb_dropout=0.3,\\n                   lin_layer_dropouts=[0.3, 0.3])\";\n",
       "                var nbb_formatted_code = \"model = Model(\\n    emb_dims,\\n    lin_layer_sizes=[300, 300],\\n    output_size=1,\\n    emb_dropout=0.3,\\n    lin_layer_dropouts=[0.3, 0.3],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model(emb_dims, lin_layer_sizes=[300, 300],\n",
    "                   output_size=1, emb_dropout=0.3,\n",
    "                   lin_layer_dropouts=[0.3, 0.3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"train_dl = SimpleDataloader.tabular_data_from_df(df = train_df,\\n                                                feature_cols = features,\\n                                                label_cols = target\\n                                                ).get_loader(batch_size = 32, num_workers = 0,\\n                                                            shuffle = True)\\n\\nvalid_dl = SimpleDataloader.tabular_data_from_df(df = valid_df,\\n                                                feature_cols = features,\\n                                                label_cols = target\\n                                                ).get_loader(batch_size = 32, num_workers = 0,\\n                                                            shuffle = False)\";\n",
       "                var nbb_formatted_code = \"train_dl = SimpleDataloader.tabular_data_from_df(\\n    df=train_df, feature_cols=features, label_cols=target\\n).get_loader(batch_size=32, num_workers=0, shuffle=True)\\n\\nvalid_dl = SimpleDataloader.tabular_data_from_df(\\n    df=valid_df, feature_cols=features, label_cols=target\\n).get_loader(batch_size=32, num_workers=0, shuffle=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dl = SimpleDataloader.tabular_data_from_df(df = train_df,\n",
    "                                                feature_cols = features,\n",
    "                                                label_cols = target\n",
    "                                                ).get_loader(batch_size = 32, num_workers = 0,\n",
    "                                                            shuffle = True)\n",
    "\n",
    "valid_dl = SimpleDataloader.tabular_data_from_df(df = valid_df,\n",
    "                                                feature_cols = features,\n",
    "                                                label_cols = target\n",
    "                                                ).get_loader(batch_size = 32, num_workers = 0,\n",
    "                                                            shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"metric_list = [metrics.Accuracy(num_classes=2, multilabel=False, threshold=0.6)]\\ncallbacks = [\\n    cbs.EarlyStopping(monitor=\\\"accuracy\\\", patience=5),\\n    cbs.ModelCheckpoint(monitor=\\\"accuracy\\\"),\\n]\";\n",
       "                var nbb_formatted_code = \"metric_list = [metrics.Accuracy(num_classes=2, multilabel=False, threshold=0.6)]\\ncallbacks = [\\n    cbs.EarlyStopping(monitor=\\\"accuracy\\\", patience=5),\\n    cbs.ModelCheckpoint(monitor=\\\"accuracy\\\"),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_list = [metrics.Accuracy(num_classes=2, multilabel=False, threshold=0.6)]\n",
    "callbacks = [\n",
    "    cbs.EarlyStopping(monitor=\"accuracy\", patience=5),\n",
    "    cbs.ModelCheckpoint(monitor=\"accuracy\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"exp = Experiment(\\n    num_epochs=10,\\n    save_dir=\\\"./models\\\",\\n    model_name=\\\"tabular_cls.bin\\\",\\n    fp16=False,\\n    using_batch_mixers=False,\\n    device=\\\"cuda\\\",\\n    compute_train_metrics=True,\\n    seed=42,\\n)\\n\\nexp.compile_experiment(\\n    model=model,\\n    optimizer=\\\"Adam\\\",\\n    optimizer_params=dict(lr=3e-4),\\n    callbacks=callbacks,\\n    scheduler=\\\"ReduceLROnPlateau\\\",\\n    scheduler_params=dict(mode=\\\"max\\\", patience=2),\\n    criterion=crit.BCEWithLogitsFlat,\\n    metrics=metric_list,\\n    main_metric=\\\"accuracy\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"exp = Experiment(\\n    num_epochs=10,\\n    save_dir=\\\"./models\\\",\\n    model_name=\\\"tabular_cls.bin\\\",\\n    fp16=False,\\n    using_batch_mixers=False,\\n    device=\\\"cuda\\\",\\n    compute_train_metrics=True,\\n    seed=42,\\n)\\n\\nexp.compile_experiment(\\n    model=model,\\n    optimizer=\\\"Adam\\\",\\n    optimizer_params=dict(lr=3e-4),\\n    callbacks=callbacks,\\n    scheduler=\\\"ReduceLROnPlateau\\\",\\n    scheduler_params=dict(mode=\\\"max\\\", patience=2),\\n    criterion=crit.BCEWithLogitsFlat,\\n    metrics=metric_list,\\n    main_metric=\\\"accuracy\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp = Experiment(\n",
    "    num_epochs=10,\n",
    "    save_dir=\"./models\",\n",
    "    model_name=\"tabular_cls.bin\",\n",
    "    fp16=False,\n",
    "    using_batch_mixers=False,\n",
    "    device=\"cuda\",\n",
    "    compute_train_metrics=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "exp.compile_experiment(\n",
    "    model=model,\n",
    "    optimizer=\"Adam\",\n",
    "    optimizer_params=dict(lr=3e-4),\n",
    "    callbacks=callbacks,\n",
    "    scheduler=\"ReduceLROnPlateau\",\n",
    "    scheduler_params=dict(mode=\"max\", patience=2),\n",
    "    criterion=crit.BCEWithLogitsFlat,\n",
    "    metrics=metric_list,\n",
    "    main_metric=\"accuracy\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Completed. Model Forward Pass and Loss Computation Successful\n",
      "Output Shape : torch.Size([32, 1])\n",
      "Loss for a batch :0.9768815636634827\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"exp.perform_sanity_check(train_dl)\";\n",
       "                var nbb_formatted_code = \"exp.perform_sanity_check(train_dl)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.perform_sanity_check(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [2/10 04:09<16:37]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.46432</td>\n",
       "      <td>0.80909</td>\n",
       "      <td>0.41868</td>\n",
       "      <td>0.81336</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.42877</td>\n",
       "      <td>0.81423</td>\n",
       "      <td>0.40852</td>\n",
       "      <td>0.81502</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12660' class='' max='13125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      96.46% [12660/13125 01:49<00:04 train_loss : 0.37504321336746216]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.run_experiment(train_dl=train_dl, valid_dl=valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
